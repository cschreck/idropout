{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/spambase.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.104553</td>\n",
       "      <td>0.213015</td>\n",
       "      <td>0.280656</td>\n",
       "      <td>0.065425</td>\n",
       "      <td>0.312223</td>\n",
       "      <td>0.095901</td>\n",
       "      <td>0.114208</td>\n",
       "      <td>0.105295</td>\n",
       "      <td>0.090067</td>\n",
       "      <td>0.239413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038575</td>\n",
       "      <td>0.139030</td>\n",
       "      <td>0.016976</td>\n",
       "      <td>0.269071</td>\n",
       "      <td>0.075811</td>\n",
       "      <td>0.044238</td>\n",
       "      <td>5.191515</td>\n",
       "      <td>52.172789</td>\n",
       "      <td>283.289285</td>\n",
       "      <td>0.394045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.305358</td>\n",
       "      <td>1.290575</td>\n",
       "      <td>0.504143</td>\n",
       "      <td>1.395151</td>\n",
       "      <td>0.672513</td>\n",
       "      <td>0.273824</td>\n",
       "      <td>0.391441</td>\n",
       "      <td>0.401071</td>\n",
       "      <td>0.278616</td>\n",
       "      <td>0.644755</td>\n",
       "      <td>...</td>\n",
       "      <td>0.243471</td>\n",
       "      <td>0.270355</td>\n",
       "      <td>0.109394</td>\n",
       "      <td>0.815672</td>\n",
       "      <td>0.245882</td>\n",
       "      <td>0.429342</td>\n",
       "      <td>31.729449</td>\n",
       "      <td>194.891310</td>\n",
       "      <td>606.347851</td>\n",
       "      <td>0.488698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.588000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.276000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.188000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.315000</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.706000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>266.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.540000</td>\n",
       "      <td>14.280000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>42.810000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.880000</td>\n",
       "      <td>7.270000</td>\n",
       "      <td>11.110000</td>\n",
       "      <td>5.260000</td>\n",
       "      <td>18.180000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.385000</td>\n",
       "      <td>9.752000</td>\n",
       "      <td>4.081000</td>\n",
       "      <td>32.478000</td>\n",
       "      <td>6.003000</td>\n",
       "      <td>19.829000</td>\n",
       "      <td>1102.500000</td>\n",
       "      <td>9989.000000</td>\n",
       "      <td>15841.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0            1            2            3            4   \\\n",
       "count  4601.000000  4601.000000  4601.000000  4601.000000  4601.000000   \n",
       "mean      0.104553     0.213015     0.280656     0.065425     0.312223   \n",
       "std       0.305358     1.290575     0.504143     1.395151     0.672513   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.420000     0.000000     0.380000   \n",
       "max       4.540000    14.280000     5.100000    42.810000    10.000000   \n",
       "\n",
       "                5            6            7            8            9   ...  \\\n",
       "count  4601.000000  4601.000000  4601.000000  4601.000000  4601.000000  ...   \n",
       "mean      0.095901     0.114208     0.105295     0.090067     0.239413  ...   \n",
       "std       0.273824     0.391441     0.401071     0.278616     0.644755  ...   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.160000  ...   \n",
       "max       5.880000     7.270000    11.110000     5.260000    18.180000  ...   \n",
       "\n",
       "                48           49           50           51           52  \\\n",
       "count  4601.000000  4601.000000  4601.000000  4601.000000  4601.000000   \n",
       "mean      0.038575     0.139030     0.016976     0.269071     0.075811   \n",
       "std       0.243471     0.270355     0.109394     0.815672     0.245882   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.065000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.188000     0.000000     0.315000     0.052000   \n",
       "max       4.385000     9.752000     4.081000    32.478000     6.003000   \n",
       "\n",
       "                53           54           55            56           57  \n",
       "count  4601.000000  4601.000000  4601.000000   4601.000000  4601.000000  \n",
       "mean      0.044238     5.191515    52.172789    283.289285     0.394045  \n",
       "std       0.429342    31.729449   194.891310    606.347851     0.488698  \n",
       "min       0.000000     1.000000     1.000000      1.000000     0.000000  \n",
       "25%       0.000000     1.588000     6.000000     35.000000     0.000000  \n",
       "50%       0.000000     2.276000    15.000000     95.000000     0.000000  \n",
       "75%       0.000000     3.706000    43.000000    266.000000     1.000000  \n",
       "max      19.829000  1102.500000  9989.000000  15841.000000     1.000000  \n",
       "\n",
       "[8 rows x 58 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chschrec/.local/share/virtualenvs/interpret-R0ok2QRq/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/chschrec/.local/share/virtualenvs/interpret-R0ok2QRq/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "df_norm = pd.DataFrame(n.fit_transform(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chschrec/.local/share/virtualenvs/interpret-R0ok2QRq/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/chschrec/.local/share/virtualenvs/interpret-R0ok2QRq/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "X = n.fit_transform(df.iloc[:,:57])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chschrec/.local/share/virtualenvs/interpret-R0ok2QRq/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "y = df.iloc[:,57:].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.601000e+03</td>\n",
       "      <td>4.601000e+03</td>\n",
       "      <td>4.601000e+03</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4.601000e+03</td>\n",
       "      <td>4.601000e+03</td>\n",
       "      <td>4.601000e+03</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4.601000e+03</td>\n",
       "      <td>4.601000e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>4.601000e+03</td>\n",
       "      <td>4.601000e+03</td>\n",
       "      <td>4.601000e+03</td>\n",
       "      <td>4.601000e+03</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4.601000e+03</td>\n",
       "      <td>4.601000e+03</td>\n",
       "      <td>4.601000e+03</td>\n",
       "      <td>4.601000e+03</td>\n",
       "      <td>4.601000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.853187e-17</td>\n",
       "      <td>2.779780e-17</td>\n",
       "      <td>2.470916e-17</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.941832e-17</td>\n",
       "      <td>3.706374e-17</td>\n",
       "      <td>-2.470916e-17</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.470916e-17</td>\n",
       "      <td>1.235458e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>1.235458e-17</td>\n",
       "      <td>-8.030476e-17</td>\n",
       "      <td>-2.470916e-17</td>\n",
       "      <td>1.235458e-17</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-9.265934e-18</td>\n",
       "      <td>1.853187e-17</td>\n",
       "      <td>1.235458e-17</td>\n",
       "      <td>2.470916e-17</td>\n",
       "      <td>-4.941832e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000109e+00</td>\n",
       "      <td>1.000109e+00</td>\n",
       "      <td>1.000109e+00</td>\n",
       "      <td>1.000109</td>\n",
       "      <td>1.000109e+00</td>\n",
       "      <td>1.000109e+00</td>\n",
       "      <td>1.000109e+00</td>\n",
       "      <td>1.000109</td>\n",
       "      <td>1.000109e+00</td>\n",
       "      <td>1.000109e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000109e+00</td>\n",
       "      <td>1.000109e+00</td>\n",
       "      <td>1.000109e+00</td>\n",
       "      <td>1.000109e+00</td>\n",
       "      <td>1.000109</td>\n",
       "      <td>1.000109e+00</td>\n",
       "      <td>1.000109e+00</td>\n",
       "      <td>1.000109e+00</td>\n",
       "      <td>1.000109e+00</td>\n",
       "      <td>1.000109e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.424337e-01</td>\n",
       "      <td>-1.650719e-01</td>\n",
       "      <td>-5.567606e-01</td>\n",
       "      <td>-0.046900</td>\n",
       "      <td>-4.643144e-01</td>\n",
       "      <td>-3.502662e-01</td>\n",
       "      <td>-2.917939e-01</td>\n",
       "      <td>-0.262562</td>\n",
       "      <td>-3.233024e-01</td>\n",
       "      <td>-3.713644e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.584534e-01</td>\n",
       "      <td>-5.143065e-01</td>\n",
       "      <td>-1.551977e-01</td>\n",
       "      <td>-3.299123e-01</td>\n",
       "      <td>-0.308355</td>\n",
       "      <td>-1.030484e-01</td>\n",
       "      <td>-1.321161e-01</td>\n",
       "      <td>-2.625994e-01</td>\n",
       "      <td>-4.656073e-01</td>\n",
       "      <td>-8.064037e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-3.424337e-01</td>\n",
       "      <td>-1.650719e-01</td>\n",
       "      <td>-5.567606e-01</td>\n",
       "      <td>-0.046900</td>\n",
       "      <td>-4.643144e-01</td>\n",
       "      <td>-3.502662e-01</td>\n",
       "      <td>-2.917939e-01</td>\n",
       "      <td>-0.262562</td>\n",
       "      <td>-3.233024e-01</td>\n",
       "      <td>-3.713644e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.584534e-01</td>\n",
       "      <td>-5.143065e-01</td>\n",
       "      <td>-1.551977e-01</td>\n",
       "      <td>-3.299123e-01</td>\n",
       "      <td>-0.308355</td>\n",
       "      <td>-1.030484e-01</td>\n",
       "      <td>-1.135824e-01</td>\n",
       "      <td>-2.369413e-01</td>\n",
       "      <td>-4.095278e-01</td>\n",
       "      <td>-8.064037e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-3.424337e-01</td>\n",
       "      <td>-1.650719e-01</td>\n",
       "      <td>-5.567606e-01</td>\n",
       "      <td>-0.046900</td>\n",
       "      <td>-4.643144e-01</td>\n",
       "      <td>-3.502662e-01</td>\n",
       "      <td>-2.917939e-01</td>\n",
       "      <td>-0.262562</td>\n",
       "      <td>-3.233024e-01</td>\n",
       "      <td>-3.713644e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.584534e-01</td>\n",
       "      <td>-2.738561e-01</td>\n",
       "      <td>-1.551977e-01</td>\n",
       "      <td>-3.299123e-01</td>\n",
       "      <td>-0.308355</td>\n",
       "      <td>-1.030484e-01</td>\n",
       "      <td>-9.189671e-02</td>\n",
       "      <td>-1.907567e-01</td>\n",
       "      <td>-3.105639e-01</td>\n",
       "      <td>-8.064037e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-3.424337e-01</td>\n",
       "      <td>-1.650719e-01</td>\n",
       "      <td>2.764271e-01</td>\n",
       "      <td>-0.046900</td>\n",
       "      <td>1.007920e-01</td>\n",
       "      <td>-3.502662e-01</td>\n",
       "      <td>-2.917939e-01</td>\n",
       "      <td>-0.262562</td>\n",
       "      <td>-3.233024e-01</td>\n",
       "      <td>-1.231813e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.584534e-01</td>\n",
       "      <td>1.811501e-01</td>\n",
       "      <td>-1.551977e-01</td>\n",
       "      <td>5.631450e-02</td>\n",
       "      <td>-0.096848</td>\n",
       "      <td>-1.030484e-01</td>\n",
       "      <td>-4.682327e-02</td>\n",
       "      <td>-4.707129e-02</td>\n",
       "      <td>-2.851691e-02</td>\n",
       "      <td>1.240074e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.452700e+01</td>\n",
       "      <td>1.090096e+01</td>\n",
       "      <td>9.560519e+00</td>\n",
       "      <td>30.641278</td>\n",
       "      <td>1.440691e+01</td>\n",
       "      <td>2.112571e+01</td>\n",
       "      <td>1.828261e+01</td>\n",
       "      <td>27.441249</td>\n",
       "      <td>1.855779e+01</td>\n",
       "      <td>2.782844e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.785384e+01</td>\n",
       "      <td>3.556066e+01</td>\n",
       "      <td>3.715432e+01</td>\n",
       "      <td>3.949191e+01</td>\n",
       "      <td>24.108447</td>\n",
       "      <td>4.608659e+01</td>\n",
       "      <td>3.458704e+01</td>\n",
       "      <td>5.099205e+01</td>\n",
       "      <td>2.566085e+01</td>\n",
       "      <td>1.240074e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0             1             2            3             4   \\\n",
       "count  4.601000e+03  4.601000e+03  4.601000e+03  4601.000000  4.601000e+03   \n",
       "mean   1.853187e-17  2.779780e-17  2.470916e-17     0.000000  4.941832e-17   \n",
       "std    1.000109e+00  1.000109e+00  1.000109e+00     1.000109  1.000109e+00   \n",
       "min   -3.424337e-01 -1.650719e-01 -5.567606e-01    -0.046900 -4.643144e-01   \n",
       "25%   -3.424337e-01 -1.650719e-01 -5.567606e-01    -0.046900 -4.643144e-01   \n",
       "50%   -3.424337e-01 -1.650719e-01 -5.567606e-01    -0.046900 -4.643144e-01   \n",
       "75%   -3.424337e-01 -1.650719e-01  2.764271e-01    -0.046900  1.007920e-01   \n",
       "max    1.452700e+01  1.090096e+01  9.560519e+00    30.641278  1.440691e+01   \n",
       "\n",
       "                 5             6            7             8             9   \\\n",
       "count  4.601000e+03  4.601000e+03  4601.000000  4.601000e+03  4.601000e+03   \n",
       "mean   3.706374e-17 -2.470916e-17     0.000000  2.470916e-17  1.235458e-17   \n",
       "std    1.000109e+00  1.000109e+00     1.000109  1.000109e+00  1.000109e+00   \n",
       "min   -3.502662e-01 -2.917939e-01    -0.262562 -3.233024e-01 -3.713644e-01   \n",
       "25%   -3.502662e-01 -2.917939e-01    -0.262562 -3.233024e-01 -3.713644e-01   \n",
       "50%   -3.502662e-01 -2.917939e-01    -0.262562 -3.233024e-01 -3.713644e-01   \n",
       "75%   -3.502662e-01 -2.917939e-01    -0.262562 -3.233024e-01 -1.231813e-01   \n",
       "max    2.112571e+01  1.828261e+01    27.441249  1.855779e+01  2.782844e+01   \n",
       "\n",
       "       ...            48            49            50            51  \\\n",
       "count  ...  4.601000e+03  4.601000e+03  4.601000e+03  4.601000e+03   \n",
       "mean   ...  1.235458e-17 -8.030476e-17 -2.470916e-17  1.235458e-17   \n",
       "std    ...  1.000109e+00  1.000109e+00  1.000109e+00  1.000109e+00   \n",
       "min    ... -1.584534e-01 -5.143065e-01 -1.551977e-01 -3.299123e-01   \n",
       "25%    ... -1.584534e-01 -5.143065e-01 -1.551977e-01 -3.299123e-01   \n",
       "50%    ... -1.584534e-01 -2.738561e-01 -1.551977e-01 -3.299123e-01   \n",
       "75%    ... -1.584534e-01  1.811501e-01 -1.551977e-01  5.631450e-02   \n",
       "max    ...  1.785384e+01  3.556066e+01  3.715432e+01  3.949191e+01   \n",
       "\n",
       "                52            53            54            55            56  \\\n",
       "count  4601.000000  4.601000e+03  4.601000e+03  4.601000e+03  4.601000e+03   \n",
       "mean      0.000000 -9.265934e-18  1.853187e-17  1.235458e-17  2.470916e-17   \n",
       "std       1.000109  1.000109e+00  1.000109e+00  1.000109e+00  1.000109e+00   \n",
       "min      -0.308355 -1.030484e-01 -1.321161e-01 -2.625994e-01 -4.656073e-01   \n",
       "25%      -0.308355 -1.030484e-01 -1.135824e-01 -2.369413e-01 -4.095278e-01   \n",
       "50%      -0.308355 -1.030484e-01 -9.189671e-02 -1.907567e-01 -3.105639e-01   \n",
       "75%      -0.096848 -1.030484e-01 -4.682327e-02 -4.707129e-02 -2.851691e-02   \n",
       "max      24.108447  4.608659e+01  3.458704e+01  5.099205e+01  2.566085e+01   \n",
       "\n",
       "                 57  \n",
       "count  4.601000e+03  \n",
       "mean  -4.941832e-17  \n",
       "std    1.000109e+00  \n",
       "min   -8.064037e-01  \n",
       "25%   -8.064037e-01  \n",
       "50%   -8.064037e-01  \n",
       "75%    1.240074e+00  \n",
       "max    1.240074e+00  \n",
       "\n",
       "[8 rows x 58 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_norm.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "import keras \n",
    "import keras.backend as K\n",
    "import innvestigate\n",
    "from keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4601"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chschrec/.local/share/virtualenvs/interpret-R0ok2QRq/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "TRAIN_SPLIT = 0.8\n",
    "TOTAL_DATA = X.shape[0]\n",
    "DATA_SPLIT = int(TRAIN_SPLIT * TOTAL_DATA)\n",
    "\n",
    "\n",
    "X_train = X[:DATA_SPLIT]\n",
    "X_test = X[DATA_SPLIT:]\n",
    "\n",
    "ohe = OneHotEncoder()\n",
    "ohe = ohe.fit(y.reshape(-1,1))\n",
    "y_bin = ohe.transform(y.reshape(-1,1))\n",
    "\n",
    "\n",
    "y_train = y_bin.todense()[:DATA_SPLIT]\n",
    "y_test = y_bin.todense()[DATA_SPLIT:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(layers=[\n",
    "    #keras.layers.Dropout(rate=0.25, input_shape=(57,), seed=0),\n",
    "    keras.layers.Dense(units=32, activation=keras.activations.relu),\n",
    "    keras.layers.Dense(units=16, activation=keras.activations.relu),\n",
    "    keras.layers.Dense(units=2, activation=keras.activations.softmax)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/chschrec/.local/share/virtualenvs/interpret-R0ok2QRq/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='Adam',\n",
    "              loss=keras.losses.categorical_crossentropy,\n",
    "              metrics=[keras.metrics.categorical_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/chschrec/.local/share/virtualenvs/interpret-R0ok2QRq/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "eps = (1/57)/10\n",
    "eps=0\n",
    "\n",
    "for ep in range(300):\n",
    "    if ep >= 10:\n",
    "        if ep % 10 == 0:\n",
    "            new_model = innvestigate.utils.model_wo_softmax(model)\n",
    "            dt_analysis = innvestigate.analyzer.DeepTaylor(new_model, neuron_selection_mode='index')\n",
    "            res_n0 = dt_analysis.analyze(X_train, 0)\n",
    "            res_n1 = dt_analysis.analyze(X_train, 1)\n",
    "            res_comb = res_n0 + res_n1\n",
    "            summed_res = np.sum(res_comb, axis=0)\n",
    "            norm_summed_res = summed_res/np.sum(summed_res)\n",
    "            mask = norm_summed_res > np.random.random(57)/57\n",
    "        X_masked = X_train * [1 if x else 0 for x in (norm_summed_res > np.random.random(57)*np.max(norm_summed_res))]\n",
    "        model.fit(X_masked, y_train, epochs=1, batch_size=128, verbose=0)\n",
    "    else:\n",
    "        model.fit(X_train, y_train, epochs=1, batch_size=128, verbose=0)\n",
    "        \n",
    "        \n",
    "    print(ep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "921/921 [==============================] - 0s 498us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.33053134484914304, 0.9261672095548317]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "921/921 [==============================] - 0s 77us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.37234137143361323, 0.8610206297502715]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "X_test_masked = X_test * [1 if np.random.rand() < 1 - 0.25 else 0 for _ in range(57)]\n",
    "\n",
    "model.evaluate(X_test_masked, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "921/921 [==============================] - 0s 78us/step\n",
      "921/921 [==============================] - 0s 82us/step\n",
      "921/921 [==============================] - 0s 84us/step\n",
      "921/921 [==============================] - 0s 98us/step\n",
      "921/921 [==============================] - 0s 86us/step\n",
      "921/921 [==============================] - 0s 86us/step\n",
      "921/921 [==============================] - 0s 80us/step\n",
      "921/921 [==============================] - 0s 87us/step\n",
      "921/921 [==============================] - 0s 90us/step\n",
      "921/921 [==============================] - 0s 98us/step\n",
      "921/921 [==============================] - 0s 84us/step\n",
      "921/921 [==============================] - 0s 85us/step\n",
      "921/921 [==============================] - 0s 96us/step\n",
      "921/921 [==============================] - 0s 88us/step\n",
      "921/921 [==============================] - 0s 79us/step\n",
      "921/921 [==============================] - 0s 85us/step\n",
      "921/921 [==============================] - 0s 86us/step\n",
      "921/921 [==============================] - 0s 87us/step\n",
      "921/921 [==============================] - 0s 94us/step\n",
      "921/921 [==============================] - 0s 95us/step\n"
     ]
    }
   ],
   "source": [
    "scores = list()\n",
    "for i in range(20):\n",
    "    np.random.seed(i)\n",
    "    X_test_masked = X_test * [1 if np.random.rand() < 1 - 0.25 else 0 for _ in range(57)]\n",
    "\n",
    "    scores.append(model.evaluate(X_test_masked, y_test)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8840933768096887"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in range(100000):\n",
    "    if np.random.rand() <0.3:\n",
    "        count +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30080"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
